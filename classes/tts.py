import edge_tts
import asyncio
import re
import os
import time
import tempfile
import logging
from typing import List, Dict, Tuple, Optional
from pydub import AudioSegment
from .settings import Settings

logger = logging.getLogger(__name__)

class TextToSpeech:
    def __init__(self, output_dir: str = "outputs"):
        """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤"""
        self.settings = Settings()
        self.output_dir = output_dir
        self.voices = self.settings.voices_list  # settings.jsonì˜ voices_list
        self.voice = self.voices.get("ì—¬ì1", "ko-KR-SunHiNeural")  # ê¸°ë³¸ ëª©ì†Œë¦¬
        self.speed = "+0%"  # ê¸°ë³¸ ì†ë„ (ë°±ë¶„ìœ¨ í˜•íƒœ)
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.output_dir, exist_ok=True)
    
    def set_voice(self, voice_key: str):
        """ëª©ì†Œë¦¬ ì„¤ì •"""
        print(f"ğŸ¤ ì„¤ì •í•  ëª©ì†Œë¦¬: '{voice_key}'")
        print(f"ğŸ¤ ì‚¬ìš© ê°€ëŠ¥í•œ ëª©ì†Œë¦¬: {list(self.voices.keys())}")
        
        if voice_key in self.voices:
            self.voice = self.voices[voice_key]
            print(f"ğŸ¤ ì„ íƒëœ ëª©ì†Œë¦¬: {self.voice}")
        else:
            print(f"ğŸ¤ ëª©ì†Œë¦¬ í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ, ì§ì ‘ ì„¤ì •: {voice_key}")
            self.voice = voice_key  # ì§ì ‘ ìŒì„± ID ì§€ì •
    
    def set_speed(self, speed: str):
        """ì†ë„ ì„¤ì • (ì˜ˆ: "0.5", "1.0", "1.5", "2.0")"""
        self.speed = speed
    
    def _convert_speed_to_rate(self, speed: str) -> str:
        """ì†ë„ë¥¼ Edge-TTS rate í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ë¶€í˜¸ ìˆëŠ” ë°±ë¶„ìœ¨ ì…ë ¥)"""
        print(f"ğŸµ ì†ë„ ë³€í™˜ ì‹œì‘: '{speed}' (íƒ€ì…: {type(speed)})")
        
        # ì´ë¯¸ ë°±ë¶„ìœ¨ í˜•íƒœì¸ì§€ í™•ì¸
        if '%' in speed:
            # ë¶€í˜¸ ìˆëŠ” ë°±ë¶„ìœ¨ í˜•íƒœë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜
            speed = speed.strip()
            print(f"ğŸµ ë°±ë¶„ìœ¨ ì…ë ¥: {speed}")
            
            # ë°±ë¶„ìœ¨ ê°’ ê²€ì¦ ë° ì •ê·œí™”
            try:
                # +50%, -20% ë“±ì—ì„œ ìˆ«ì ë¶€ë¶„ ì¶”ì¶œ
                match = re.match(r'([+-]?\d+)%', speed)
                if match:
                    percentage = int(match.group(1))
                    # ë²”ìœ„ ì œí•œ: -50% ~ +100%
                    percentage = max(-50, min(100, percentage))
                    result = f"{percentage:+d}%"
                    print(f"ğŸµ ì •ê·œí™”ëœ ë°±ë¶„ìœ¨: {result}")
                    return result
                else:
                    print(f"ğŸµ ì˜ëª»ëœ ë°±ë¶„ìœ¨ í˜•ì‹: {speed}")
                    return "+0%"
            except:
                print(f"ğŸµ ë°±ë¶„ìœ¨ íŒŒì‹± ì˜¤ë¥˜: {speed}")
                return "+0%"
        
        # ë ˆê±°ì‹œ ìˆ«ì í˜•íƒœ (1.5 ë“±) ì§€ì› - ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜
        try:
            speed_float = float(speed)
            print(f"ğŸµ ë ˆê±°ì‹œ ìˆ«ì ì…ë ¥: {speed_float}")
            
            if speed_float <= 0.0:
                result = "-50%"  # ìµœì†Œ ì†ë„
            elif speed_float < 1.0:
                # 0.5 ~ 1.0 ë²”ìœ„: -50% ~ 0%
                if speed_float <= 0.5:
                    percentage = -50
                else:
                    percentage = int((speed_float - 0.5) / 0.5 * 50 - 50)
                result = f"{percentage:+d}%"
            elif speed_float == 1.0:
                result = "+0%"  # ê¸°ë³¸ ì†ë„
            elif speed_float <= 2.0:
                # 1.0 ~ 2.0 ë²”ìœ„: 0% ~ +100%
                percentage = int((speed_float - 1.0) / 1.0 * 100)
                result = f"+{percentage}%"
            else:
                result = "+100%"
            
            print(f"ğŸµ ë ˆê±°ì‹œ ë³€í™˜ ê²°ê³¼: {result}")
            return result
        except:
            print(f"ğŸµ ì†ë„ ë³€í™˜ ì˜¤ë¥˜: {speed}")
            return "+0%"
    
    def _convert_percentage_to_multiplier(self, speed: str) -> float:
        """ë°±ë¶„ìœ¨ ì†ë„ë¥¼ ë°°ìˆ˜ë¡œ ë³€í™˜ (pydubìš©)"""
        if '%' in speed:
            try:
                # +50%, -20% ë“±ì—ì„œ ìˆ«ì ë¶€ë¶„ ì¶”ì¶œ
                match = re.match(r'([+-]?\d+)%', speed)
                if match:
                    percentage = int(match.group(1))
                    # ë°±ë¶„ìœ¨ì„ ë°°ìˆ˜ë¡œ ë³€í™˜: +50% = 1.5ë°°, -20% = 0.8ë°°
                    multiplier = 1.0 + (percentage / 100.0)
                    return max(0.1, min(3.0, multiplier))  # 0.1~3.0 ë²”ìœ„ ì œí•œ
                else:
                    return 1.0
            except:
                return 1.0
        else:
            # ë ˆê±°ì‹œ ìˆ«ì í˜•íƒœ
            try:
                return float(speed)
            except:
                return 1.0
    
    def _extract_voice_speed_options(self, text: str) -> Tuple[str, Optional[str], Optional[str]]:
        """í…ìŠ¤íŠ¸ì—ì„œ ëª©ì†Œë¦¬ì™€ ì†ë„ ì˜µì…˜ì„ ì¶”ì¶œí•˜ê³  ì •ë¦¬ëœ í…ìŠ¤íŠ¸ ë°˜í™˜"""
        voice = None
        speed = None
        clean_text = text
        
        print(f"ğŸ” ì˜µì…˜ ì¶”ì¶œ ì‹œì‘: '{text}'")
        
        # ëª©ì†Œë¦¬ ì˜µì…˜ íŒ¨í„´
        voice_pattern = r'\[(ëª©ì†Œë¦¬|VOICE):([^\]]+)\]'
        voice_match = re.search(voice_pattern, text)
        if voice_match:
            voice = voice_match.group(2)
            clean_text = re.sub(voice_pattern, '', clean_text)
            print(f"ğŸ¤ ëª©ì†Œë¦¬ ì˜µì…˜ ë°œê²¬: {voice}")
        
        # ì†ë„ ì˜µì…˜ íŒ¨í„´
        speed_pattern = r'\[(ì†ë„|SPEED):([^\]]+)\]'
        speed_match = re.search(speed_pattern, text)
        if speed_match:
            speed = speed_match.group(2)
            clean_text = re.sub(speed_pattern, '', clean_text)
            print(f"ğŸµ ì†ë„ ì˜µì…˜ ë°œê²¬: {speed}")
        
        # ê¸°íƒ€ ì˜µì…˜ ì œê±° (GIPHY, GOOGLE ë“±)
        other_pattern = r'\[(GIPHY|GOOGLE|GIPHY_URL|GOOGLE_URL|ê²€ìƒ‰ì–´):([^\]]+)\]'
        clean_text = re.sub(other_pattern, '', clean_text)
        
        print(f"ğŸ” ì¶”ì¶œ ê²°ê³¼ - ìŒì„±: {voice}, ì†ë„: {speed}, ì •ë¦¬ëœ í…ìŠ¤íŠ¸: '{clean_text.strip()}'")
        return clean_text.strip(), voice, speed
    
    def _process_line_with_pauses(self, line: str) -> List[Dict]:
        """í•œ ì¤„ì˜ í…ìŠ¤íŠ¸ë¥¼ ì‰¼ ëª…ë ¹ì–´ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ì²˜ë¦¬"""
        # ì‰¼ ëª…ë ¹ì–´ íŒ¨í„´
        pause_pattern = r'\[ì‰¼:([^\]]+)\]'
        
        segments = []
        current_pos = 0
        
        for match in re.finditer(pause_pattern, line):
            # ì‰¼ ëª…ë ¹ì–´ ì•ì˜ í…ìŠ¤íŠ¸
            before_text = line[current_pos:match.start()].strip()
            if before_text:
                segments.append({'type': 'text', 'content': before_text})
            
            # ì‰¼ ëª…ë ¹ì–´
            try:
                pause_duration = float(match.group(1))
                segments.append({'type': 'pause', 'duration': pause_duration})
            except ValueError:
                pass
            
            current_pos = match.end()
        
        # ë§ˆì§€ë§‰ ë‚¨ì€ í…ìŠ¤íŠ¸
        remaining_text = line[current_pos:].strip()
        if remaining_text:
            segments.append({'type': 'text', 'content': remaining_text})
        
        return segments
    
    async def convert(self, text: str) -> Dict:
        """
        í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
        
        ë™ì‘ ë°©ì‹:
        1. ì¤„ë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ ì²˜ë¦¬
        2. ê° ì¤„ì—ì„œ ëª©ì†Œë¦¬/ì†ë„ ì˜µì…˜ì´ ìˆìœ¼ë©´ ê·¸ ì¤„ ì „ì²´ì— ì ìš© (ì¤„ë°”ê¿ˆ ì „ê¹Œì§€ ìœ ì§€)
        3. ì‰¼ ëª…ë ¹ì–´ëŠ” ê·¸ ìë¦¬ì—ì„œ ì¦‰ì‹œ ë¬´ìŒ ì‚½ì…
        4. ë‹¤ìŒ ì¤„ë¡œ ë„˜ì–´ê°€ë©´ ëª©ì†Œë¦¬/ì†ë„ëŠ” ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
        
        Args:
            text: ë³€í™˜í•  í…ìŠ¤íŠ¸
            
        Returns:
            dict: 
                - success: ì„±ê³µ ì—¬ë¶€
                - audio_path: ìƒì„±ëœ ìŒì„± íŒŒì¼ ê²½ë¡œ (ì„±ê³µì‹œ)
                - error: ì˜¤ë¥˜ ë©”ì‹œì§€ (ì‹¤íŒ¨ì‹œ)
                - subtitles: ìë§‰ ì •ë³´ (ì„±ê³µì‹œ)
        """
        try:
            if not text.strip():
                return {
                    'success': False,
                    'error': 'ë³€í™˜í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.'
                }
            
            # ì¤„ë³„ë¡œ ë¶„ë¦¬
            lines = text.strip().split('\n')
            audio_segments = []
            subtitles = []
            current_time = 0.0
            
            for line in lines:
                if not line.strip():
                    continue
                
                # ì´ ì¤„ì—ì„œ ëª©ì†Œë¦¬/ì†ë„ ì˜µì…˜ ì¶”ì¶œ (ì¤„ ì „ì²´ì— ì ìš©)
                line_without_options, line_voice, line_speed = self._extract_voice_speed_options(line)
                
                # ì´ ì¤„ì—ì„œ ì‚¬ìš©í•  ëª©ì†Œë¦¬ì™€ ì†ë„ ì„¤ì •
                current_voice = self.voice  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì‹œì‘
                current_rate = self._convert_speed_to_rate(self.speed)  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì‹œì‘
                
                if line_voice:
                    if line_voice in self.voices:
                        current_voice = self.voices[line_voice]
                    else:
                        current_voice = line_voice  # ì§ì ‘ ì§€ì •ëœ ìŒì„±
                
                if line_speed:
                    current_rate = self._convert_speed_to_rate(line_speed)
                    print(f"ğŸµ ì¤„ë³„ ì†ë„ ì„¤ì •: {line_speed} -> {current_rate}")
                
                print(f"ğŸ¤ í˜„ì¬ ìŒì„±: {current_voice}, ì†ë„: {current_rate}")
                
                # ì´ ì¤„ì„ ì‰¼ ëª…ë ¹ì–´ ê¸°ì¤€ìœ¼ë¡œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¦¬
                segments = self._process_line_with_pauses(line_without_options)
                
                for segment in segments:
                    if segment['type'] == 'pause':
                        # ì‰¼ ëª…ë ¹ì–´ ì²˜ë¦¬ - ë¬´ìŒ ì¶”ê°€
                        duration = segment['duration']
                        silence = AudioSegment.silent(duration=int(duration * 1000))
                        audio_segments.append(silence)
                        current_time += duration
                        
                    elif segment['type'] == 'text':
                        clean_text = segment['content'].strip()
                        if not clean_text:
                            continue
                        
                        # Edge-TTSë¡œ ìŒì„± ìƒì„±
                        print(f"ğŸµ TTS ìƒì„± ì „ - í…ìŠ¤íŠ¸: '{clean_text}', ìŒì„±: {current_voice}, ì†ë„: {current_rate}")
                        
                        # Edge-TTSì—ì„œ ì†ë„ ì„¤ì • ë°©ë²• ê°œì„ 
                        tts_communicate = edge_tts.Communicate(
                            text=clean_text,
                            voice=current_voice,
                            rate=current_rate  # ìƒì„±ìì—ì„œ ì§ì ‘ ì„¤ì •
                        )
                        
                        print(f"ğŸµ TTS ê°ì²´ ì„¤ì • ì™„ë£Œ - rate: {current_rate}")
                        
                        # ì„ì‹œ íŒŒì¼ì— ì €ì¥
                        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
                        temp_file.close()
                        
                        print(f"ğŸµ ìŒì„± íŒŒì¼ ìƒì„± ì‹œì‘: {temp_file.name}")
                        start_time = time.time()
                        
                        try:
                            await tts_communicate.save(temp_file.name)
                            end_time = time.time()
                            generation_time = end_time - start_time
                            print(f"ğŸµ ìŒì„± íŒŒì¼ ìƒì„± ì™„ë£Œ: {generation_time:.2f}ì´ˆ ì†Œìš”")
                            
                            # AudioSegmentë¡œ ë¡œë“œ
                            audio_segment = AudioSegment.from_mp3(temp_file.name)
                            
                            # ì†ë„ ì¡°ì ˆì„ pydubë¡œ ì²˜ë¦¬ (Edge-TTSê°€ ì œëŒ€ë¡œ ì ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°)
                            if line_speed and line_speed not in ["1.0", "+0%"]:
                                speed_multiplier = self._convert_percentage_to_multiplier(line_speed)
                                print(f"ğŸµ pydubë¡œ ì†ë„ ì¡°ì ˆ: {line_speed} -> {speed_multiplier}ë°°")
                                
                                # ì†ë„ ì¡°ì ˆ: ë¹ ë¥´ê²Œ í•˜ë ¤ë©´ frame_rateë¥¼ ë†’ì´ê³ , ëŠë¦¬ê²Œ í•˜ë ¤ë©´ ë‚®ì¶˜ë‹¤
                                # ê·¸ í›„ ì›ë˜ sample_rateë¡œ ë˜ëŒë¦°ë‹¤
                                if speed_multiplier != 1.0:
                                    # ì†ë„ ì¡°ì ˆ ì ìš©
                                    new_sample_rate = int(audio_segment.frame_rate * speed_multiplier)
                                    audio_segment = audio_segment._spawn(audio_segment.raw_data, 
                                                                       overrides={"frame_rate": new_sample_rate})
                                    audio_segment = audio_segment.set_frame_rate(22050)  # ì›ë˜ ìƒ˜í”Œë ˆì´íŠ¸ë¡œ ë³µì›
                            
                            segment_duration = len(audio_segment) / 1000.0
                            print(f"ğŸµ ìµœì¢… ìŒì„± ê¸¸ì´: {segment_duration:.2f}ì´ˆ")
                            
                            audio_segments.append(audio_segment)
                            
                            # ìë§‰ ì •ë³´ ì¶”ê°€
                            subtitles.append({
                                'start_time': current_time,
                                'end_time': current_time + segment_duration,
                                'text': clean_text
                            })
                            current_time += segment_duration
                            
                        finally:
                            if os.path.exists(temp_file.name):
                                os.unlink(temp_file.name)
            
            if not audio_segments:
                return {
                    'success': False,
                    'error': 'ë³€í™˜í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.'
                }
            
            # ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ í•©ì¹˜ê¸°
            final_audio = audio_segments[0]
            for segment in audio_segments[1:]:
                final_audio += segment
            
            # ìµœì¢… íŒŒì¼ ì €ì¥
            output_path = os.path.join(self.output_dir, f"tts_{int(time.time())}.mp3")
            final_audio.export(output_path, format="mp3")
            
            return {
                'success': True,
                'audio_path': output_path,
                'subtitles': subtitles
            }
            
        except Exception as e:
            logger.error(f"TTS ë³€í™˜ ì˜¤ë¥˜: {str(e)}")
            return {
                'success': False,
                'error': f"TTS ë³€í™˜ ì‹¤íŒ¨: {str(e)}"
            }
    
    def subtitles_to_srt(self, subtitles: List[Dict]) -> str:
        """ìë§‰ ì •ë³´ë¥¼ SRT í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        srt_content = []
        
        for i, subtitle in enumerate(subtitles, 1):
            start_time = self._seconds_to_srt_time(subtitle['start_time'])
            end_time = self._seconds_to_srt_time(subtitle['end_time'])
            text = subtitle['text']
            
            srt_content.append(f"{i}")
            srt_content.append(f"{start_time} --> {end_time}")
            srt_content.append(text)
            srt_content.append("")  # ë¹ˆ ì¤„
        
        return '\n'.join(srt_content)
    
    def _seconds_to_srt_time(self, seconds: float) -> str:
        """ì´ˆë¥¼ SRT ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (HH:MM:SS,mmm)"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds % 1) * 1000)
        
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"